import feedparser
import google.generativeai as genai
import requests
import time
from datetime import datetime, timedelta
from time import mktime
import os
from bs4 import BeautifulSoup

# Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯Ù‡Ø§
TELEGRAM_TOKEN = os.environ["TELEGRAM_TOKEN"]
CHANNEL_ID = os.environ["CHANNEL_ID"]
GEMINI_API_KEY = os.environ["GEMINI_API_KEY"]

# Ù„ÛŒØ³Øª Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ (Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø±Ø§ Ù‡Ù… Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒ)
RSS_URLS = [
    "https://www.zoomit.ir/feed/",
    # "https://digiato.com/feed",
]

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash-lite')

HISTORY_FILE = "history.txt"

def load_history():
    """Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡"""
    if not os.path.exists(HISTORY_FILE):
        return []
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return [line.strip() for line in f.readlines() if line.strip()]

def save_to_history(link, title):
    """Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú© Ùˆ ØªÛŒØªØ± Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ùˆ Ú©Ø§Ù…ÛŒØª Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨"""
    try:
        with open(HISTORY_FILE, "a", encoding="utf-8") as f:
            f.write(f"{link}|{title}\n")
        
        # Ø¯Ø³ØªÙˆØ±Ø§Øª Ú¯ÛŒØª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¦Ù…ÛŒ
        os.system(f'git config --global user.name "News Bot"')
        os.system(f'git config --global user.email "bot@noreply.github.com"')
        os.system(f'git add {HISTORY_FILE}')
        os.system('git commit -m "Update history log"')
        os.system('git push')
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")

def check_is_duplicate_topic(new_title, history_lines):
    """Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…ÛŒâ€ŒÙ¾Ø±Ø³Ø¯ Ø¢ÛŒØ§ Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾ÙˆØ´Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ØŸ"""
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ Ù‡ÛŒØ³ØªÙˆØ±ÛŒ (50 ØªØ§ÛŒ Ø¢Ø®Ø±) <--- ØªØºÛŒÛŒØ± Ø§ÛŒÙ†Ø¬Ø§Ø³Øª
    recent_titles = []
    
    # Ø§ÛŒÙ†Ø¬Ø§ Ø¹Ø¯Ø¯ Ø±Ø§ Ø¨Ù‡ 50 ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯ÛŒÙ… ØªØ§ Ø­Ø§ÙØ¸Ù‡ Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
    for line in history_lines[-50:]: 
        parts = line.split("|")
        if len(parts) > 1:
            recent_titles.append(parts[1])
    
    if not recent_titles:
        return False 

    prompt = f"""
    Ù…Ù† Ù„ÛŒØ³ØªÛŒ Ø§Ø² ÛµÛ° ØªÛŒØªØ± Ø®Ø¨Ø±ÛŒ Ú©Ù‡ Ø§Ø®ÛŒØ±Ø§Ù‹ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ú¯Ø°Ø§Ø´ØªÙ… Ø¯Ø§Ø±Ù…:
    {recent_titles}

    ÛŒÚ© Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø¢Ù…Ø¯Ù‡ Ø¨Ø§ Ø§ÛŒÙ† ØªÛŒØªØ±:
    "{new_title}"

    Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯ØŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…Ø§Ù† Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Ú©Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ù„ÛŒØ³Øª Ø¨Ø§Ù„Ø§ Ú¯ÙØªÙ‡ØŸ 
    (Ø­Ø³Ø§Ø³ÛŒØª Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´. Ø§Ú¯Ø± Ø´Ú© Ø¯Ø§Ø´ØªÛŒ Ú©Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø³ØªØŒ Ø¨Ú¯Ùˆ YES).
    ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡: YES ÛŒØ§ NO
    """
    try:
        response = model.generate_content(prompt)
        text = response.text.strip().upper()
        if "YES" in text:
            return True
        return False
    except:
        return False

def send_to_telegram(message, image_url=None):
    try:
        if image_url:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto"
            data = {"chat_id": CHANNEL_ID, "photo": image_url, "caption": message, "parse_mode": "Markdown"}
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            data = {"chat_id": CHANNEL_ID, "text": message, "parse_mode": "Markdown"} 
        requests.post(url, data=data)
    except Exception as e:
        print(f"Error sending: {e}")

def extract_image(entry):
    if 'media_content' in entry:
        for media in entry.media_content:
            if 'url' in media: return media['url']
    if 'links' in entry:
        for link in entry.links:
            if link.type.startswith('image/'): return link.href
    if 'summary' in entry:
        soup = BeautifulSoup(entry.summary, 'html.parser')
        img = soup.find('img')
        if img and 'src' in img.attrs: return img['src']
    return None

def summarize_with_ai(title, content):
    prompt = f"""
    Ø§Ø¯Ù…ÛŒÙ† Ú©Ø§Ù†Ø§Ù„ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ù‡Ø³ØªÛŒ.
    Ø®Ø¨Ø±: {title}
    Ù…ØªÙ†: {content}
    ÙˆØ¸Ø§ÛŒÙ:
    1. Ù…ØªÙ† Ø¬Ø°Ø§Ø¨ØŒ Ú©ÙˆØªØ§Ù‡ (3 Ø®Ø·).
    2. Ø¨Ø¯ÙˆÙ† Ù„ÛŒÙ†Ú© Ù…Ù†Ø¨Ø¹.
    3. Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¯Ø§Ø±.
    4. Ø¢Ø®Ø±Ø´ Ø¨Ù†ÙˆÛŒØ³: ğŸ†” @Teklp
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except:
        return None

def check_feeds():
    print("Reading history...")
    history_lines = load_history()
    history_links = [line.split("|")[0] for line in history_lines]

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø®Ø¨Ø§Ø± 6 Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ±
    time_threshold = datetime.now() - timedelta(hours=6)
    
    for url in RSS_URLS:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                if hasattr(entry, 'published_parsed'):
                    pub_date = datetime.fromtimestamp(mktime(entry.published_parsed))
                    
                    if pub_date > time_threshold:
                        # ÙÛŒÙ„ØªØ± Û±: Ù„ÛŒÙ†Ú© ØªÚ©Ø±Ø§Ø±ÛŒ
                        if entry.link in history_links:
                            print(f"ØªÚ©Ø±Ø§Ø±ÛŒ (Ù„ÛŒÙ†Ú©): {entry.title}")
                            continue
                        
                        # ÙÛŒÙ„ØªØ± Û²: Ù…ÙˆØ¶ÙˆØ¹ ØªÚ©Ø±Ø§Ø±ÛŒ (Ú†Ú© Ú©Ø±Ø¯Ù† Ø¨Ø§ ÛµÛ° Ø®Ø¨Ø± Ø¢Ø®Ø±)
                        if check_is_duplicate_topic(entry.title, history_lines):
                            print(f"ØªÚ©Ø±Ø§Ø±ÛŒ (Ù…ÙˆØ¶ÙˆØ¹): {entry.title}")
                            save_to_history(entry.link, entry.title)
                            continue

                        print(f"Ø®Ø¨Ø± ÛŒÙˆÙ†ÛŒÚ©: {entry.title}")
                        image_url = extract_image(entry)
                        summary = summarize_with_ai(entry.title, entry.summary)
                        
                        if summary:
                            final_text = f"ğŸ”¥ **{entry.title}**\n\n{summary}"
                            send_to_telegram(final_text, image_url)
                            save_to_history(entry.link, entry.title)
                            time.sleep(5)
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    check_feeds()
